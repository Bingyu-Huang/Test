
Baseline: Conditional Diffusion Model
Difficulty Analysis:
The basic architecture can be modified directly based on the existing diffusion model (such as DDPM), and only the event encoder and conditional injection module need to be added.
The main challenge is the fusion design of event features and the time step condition (t) of the diffusion model (such as cross attention or feature splicing).
Recommended tools:
PyTorch + diffusers library (Hugging Face), which supports fast implementation of conditional diffusion.
Experimental suggestions:
Start with simple feature splicing and gradually try the attention mechanism.
1. I'll use basicsr framework github.com/XPixelGroup/BasicSR to build up my project. Here's the initial frame.
EventDeblur/
├── basicsr/ # You can use the core part of BasicSR directly or modify it
│ ├── archs/ # Model architecture directory
│ ├── data/ # Data processing directory
│ ├── losses/ # Loss function directory
│ ├── metrics/ # Evaluation indicator directory
│ ├── models/ # Model training/test process directory
│ ├── ops/ # Custom operation directory
│ └── utils/ # Tool function directory
├── options/ # Configuration file directory
│ ├── train/ # Training configuration
│ └── test/ # Test configuration
├── scripts/ # Script directory
│ ├── train.sh # Training script
│ └── test.sh # Test script
├── tb_logger/ # TensorBoard log
├── experiments/ # Experimental results directory
├── results/ # Final results directory
├── docs/ # Documentation
├── README.md # Project description
├── requirements.txt # Project dependencies
└── setup.py # Installation script
2. Main implementation files
Here are the files you need to focus on and implement:
a. Model architecture (basicsr/archs/)
Create the following files:

event_encoder_arch.py ​​- Event data encoder architecture
diffusion_arch.py ​​- Conditional diffusion model architecture
unet_arch.py ​​- U-Net backbone network architecture
fusion_module_arch.py ​​- Feature fusion module architecture

b. Data processing (basicsr/data/)

Create the following files:

event_deblur_dataset.py - Event-blurred image pair dataset
event_data_util.py - Event data processing tool

c. Model training/testing process (basicsr/models/)
Create the following files:

event_diffusion_model.py - training/testing process of event conditional diffusion model

d. Configuration files (options/)
Create the following files:

train/train_event_diffusion.yml - training configuration
test/test_event_diffusion.yml - test configuration
3.Regarding the core files, I need to introduce my dataset to you. I plan to test two datasets, one is GOPRO and the other is REBlur. Let me first introduce the structure of the GOPRO dataset. The structure of the GOPRO dataset is classified by scene. Each scene folder contains blur, blur_gamma, event, sharp and voxel subfolders. In order to speed up the training, I preprocessed the event and saved it directly to the voxel folder. One voxel package corresponds to one blur image. I will use blur_gamma (gamma-corrected image) for blur image, and I will directly use voxel (shape=[BINS=5, H,W,2], the last dimension stores positive and negative polarity) as event input.
4. I'll use WandB to supervise the training process.

Project Implementation Plan
Phase 1: Project Setup and Data Pipeline

Set up the BasicSR framework and create the project structure
Implement the dataset class for handling event-RGB pairs
Create data loading and preprocessing utilities for event data
Test the data pipeline to ensure proper loading of images and voxel data

Phase 2: Model Architecture

Design and implement the event encoder architecture
Implement the U-Net backbone for the diffusion model
Create the feature fusion module to combine event and image features
Implement the conditional diffusion model architecture
Test each component individually to ensure they work as expected

Phase 3: Training and Evaluation

Set up the loss functions and optimization strategy
Implement the training loop and validation process
Configure WandB for experiment tracking
Create configuration files for different experiments
Write evaluation metrics for deblurring quality assessment

Phase 4: Testing and Refinement

Implement inference code for model testing
Create visualization utilities for qualitative assessment
Optimize model performance and hyperparameters
Document the project thoroughly for future reference

Let's start with Phase 1 by setting up the project structure and implementing the dataset class. Would you like me to proceed with the implementation of the data pipeline first?
